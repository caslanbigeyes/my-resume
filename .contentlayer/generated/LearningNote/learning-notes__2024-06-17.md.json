{
  "title": "æœºå™¨å­¦ä¹ 03 - AIE54 Day03å­¦ä¹ ç¬”è®°",
  "date": "2024-06-17T00:00:00.000Z",
  "summary": "æœºå™¨å­¦ä¹ ç¬¬ä¸‰å¤©å­¦ä¹ å†…å®¹ï¼ŒåŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€æ¨¡å‹è¯„ä¼°å’Œæ¨¡å‹ä¿å­˜",
  "tags": [
    "æœºå™¨å­¦ä¹ ",
    "çº¿æ€§å›å½’",
    "é€»è¾‘å›å½’",
    "æ•°æ®é¢„å¤„ç†",
    "æ¨¡å‹è¯„ä¼°",
    "AIE54"
  ],
  "readingTime": 18,
  "hasImages": true,
  "slug": "2024-06-17",
  "body": {
    "raw": "\n# æœºå™¨å­¦ä¹ 03 - AIE54 Day03å­¦ä¹ ç¬”è®°\n\n> **å­¦ä¹ æ—¥æœŸ**ï¼š2024-06-17  \n> **ä¸»è®²è€å¸ˆ**ï¼šææ™“å  \n> **è¯¾æ—¶**ï¼š2  \n> **æ–‡æ¡£æ¥æº**ï¼šday03-æœºå™¨å­¦ä¹ 03.pdf\n\n## è¯¾ç¨‹å…³é”®è¯\næœºå™¨å­¦ä¹  | æ•°æ®é¢„å¤„ç† | çº¿æ€§å›å½’ | é€»è¾‘å›å½’ | æ¨¡å‹è¯„ä¼° | KNNç®—æ³•\n\n---\n\n## ğŸ¯ ç¬¬ä¸€éƒ¨åˆ†ï¼šæœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µ\n\n### 1.1 æœ‰ç›‘ç£å­¦ä¹ æµç¨‹\n\n**æ ‡å‡†æœºå™¨å­¦ä¹ æµç¨‹**åŒ…æ‹¬ä»¥ä¸‹å…³é”®æ­¥éª¤ï¼š\n\n1. **æ•°æ®æ”¶é›†ä¸åŠ è½½**\n2. **ç‰¹å¾å·¥ç¨‹ä¸æ•°æ®é¢„å¤„ç†**\n3. **æ¨¡å‹é€‰æ‹©ä¸è®­ç»ƒ**\n4. **æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–**\n5. **æ¨¡å‹éƒ¨ç½²ä¸ä¿å­˜**\n\n### 1.2 å›å½’ vs åˆ†ç±»\n\n**æ ¸å¿ƒåŒºåˆ«**ï¼š\n\n- **å›å½’é—®é¢˜**ï¼šé¢„æµ‹è¿ç»­æ•°å€¼ï¼ˆå¦‚æˆ¿ä»·é¢„æµ‹ã€æ¸©åº¦é¢„æµ‹ï¼‰\n- **åˆ†ç±»é—®é¢˜**ï¼šé¢„æµ‹ç¦»æ•£ç±»åˆ«ï¼ˆå¦‚ç–¾ç—…è¯Šæ–­ã€å›¾åƒè¯†åˆ«ï¼‰\n\n**åº”ç”¨åœºæ™¯**ï¼š\n- å›å½’ï¼šè‚¡ä»·é¢„æµ‹ã€é”€é‡é¢„æµ‹ã€å¹´é¾„ä¼°è®¡\n- åˆ†ç±»ï¼šåƒåœ¾é‚®ä»¶æ£€æµ‹ã€æƒ…æ„Ÿåˆ†æã€åŒ»ç–—è¯Šæ–­\n\n---\n\n## ğŸ”§ ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®é¢„å¤„ç†ä¸æ ‡å‡†åŒ–\n\n### 2.1 æ•°æ®æ ‡å‡†åŒ–çš„é‡è¦æ€§\n\n**æ ¸å¿ƒç›®çš„**ï¼šæ¶ˆé™¤ä¸åŒç‰¹å¾ä¹‹é—´é‡çº²å·®å¼‚çš„å½±å“ï¼Œç¡®ä¿æ‰€æœ‰ç‰¹å¾åœ¨ç›¸åŒå°ºåº¦ä¸Šå‚ä¸æ¨¡å‹è®­ç»ƒã€‚\n\n**ä¸ºä»€ä¹ˆéœ€è¦æ ‡å‡†åŒ–ï¼Ÿ**\n- ä¸åŒç‰¹å¾çš„æ•°å€¼èŒƒå›´å¯èƒ½ç›¸å·®å·¨å¤§\n- å¤§æ•°å€¼ç‰¹å¾ä¼šä¸»å¯¼æ¨¡å‹å­¦ä¹ è¿‡ç¨‹\n- å½±å“åŸºäºè·ç¦»çš„ç®—æ³•ï¼ˆå¦‚KNNã€SVMï¼‰\n\n### 2.2 æ ‡å‡†åŒ–å…¬å¼\n\n**Z-score æ ‡å‡†åŒ–å…¬å¼**ï¼š\n\nX_normalized = (X - Î¼) / (Ïƒ + Îµ)\n\nå…¶ä¸­ï¼š\n- Î¼ æ˜¯å‡å€¼\n- Ïƒ æ˜¯æ ‡å‡†å·®  \n- Îµ = 1e-9 æ˜¯é˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°\n\n### 2.3 ä»£ç å®ç°\n\n```python\n# è®¡ç®—è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·®\nmu = X_train.mean(axis=0)\nsigma = X_train.std(axis=0) + 1e-9\n\n# å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œæ ‡å‡†åŒ–\nX_train = (X_train - mu) / sigma\nX_test = (X_test - mu) / sigma\n```\n\n**âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹**ï¼š\n- æµ‹è¯•é›†å¿…é¡»ä½¿ç”¨è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·®è¿›è¡Œæ ‡å‡†åŒ–\n- é¿å…æ•°æ®æ³„éœ²é—®é¢˜\n- ä¿è¯æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›\n\n---\n\n## ğŸ“ˆ ç¬¬ä¸‰éƒ¨åˆ†ï¼šçº¿æ€§å›å½’\n\n### 3.1 ç†è®ºåŸºç¡€\n\n**çº¿æ€§å›å½’å‡è®¾**ï¼šç›®æ ‡å˜é‡ä¸ç‰¹å¾å˜é‡ä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»\n\n**æ•°å­¦è¡¨è¾¾å¼**ï¼š\ny = wâ‚€ + wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™ + Îµ\n\nå…¶ä¸­ï¼š\n- y æ˜¯ç›®æ ‡å˜é‡\n- wáµ¢ æ˜¯æƒé‡å‚æ•°\n- xáµ¢ æ˜¯ç‰¹å¾å˜é‡\n- Îµ æ˜¯è¯¯å·®é¡¹\n\n### 3.2 æŸå¤±å‡½æ•°\n\n**å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**ä½œä¸ºæŸå¤±å‡½æ•°ï¼š\n\nMSE = (1/n) Ã— Î£áµ¢â‚Œâ‚â¿ (yáµ¢ - Å·áµ¢)Â²\n\n**ç‰¹ç‚¹**ï¼š\n- å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ\n- å¯å¯¼ï¼Œä¾¿äºä¼˜åŒ–\n- å‡ ä½•æ„ä¹‰æ˜ç¡®\n\n### 3.3 å®Œæ•´ä»£ç ç¤ºä¾‹\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# 1. æ•°æ®åŠ è½½\ndata = pd.read_csv(\"boston_house_prices.csv\", skiprows=1)\n\n# 2. ç‰¹å¾å’Œæ ‡ç­¾åˆ†ç¦»\nX = data.loc[:, :\"LSTAT\"].to_numpy()  # ç‰¹å¾\ny = data.loc[:, \"MEDV\"].to_numpy()    # æ ‡ç­¾\n\n# 3. æ•°æ®åˆ‡åˆ†\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=0\n)\n\n# 4. æ•°æ®æ ‡å‡†åŒ–\nmu = X_train.mean(axis=0)\nsigma = X_train.std(axis=0) + 1e-9\nX_train = (X_train - mu) / sigma\nX_test = (X_test - mu) / sigma\n\n# 5. æ¨¡å‹è®­ç»ƒ\nlr = LinearRegression()\nlr.fit(X=X_train, y=y_train)\n\n# 6. é¢„æµ‹ä¸è¯„ä¼°\ny_pred = lr.predict(X=X_test)\nmse = ((y_pred - y_test) ** 2).mean()\nprint(f\"å‡æ–¹è¯¯å·®: {mse}\")\n```\n\n---\n\n## ğŸ§  ç¬¬å››éƒ¨åˆ†ï¼šé€»è¾‘å›å½’ä¸åˆ†ç±»\n\n### 4.1 Sigmoid æ¿€æ´»å‡½æ•°\n\n**æ ¸å¿ƒä½œç”¨**ï¼šå°†çº¿æ€§è¾“å‡ºæ˜ å°„åˆ° (0,1) åŒºé—´ï¼Œè¡¨ç¤ºæ¦‚ç‡\n\n**æ•°å­¦å…¬å¼**ï¼š\nÏƒ(z) = 1 / (1 + e^(-z))\n\n### 4.2 Sigmoid å‡½æ•°ç‰¹æ€§\n\n**é‡è¦ç‰¹æ€§**ï¼š\n- **è¾“å‡ºèŒƒå›´**ï¼š(0, 1)\n- **Så‹æ›²çº¿**ï¼šå¹³æ»‘çš„æ¦‚ç‡è½¬æ¢\n- **å¯¼æ•°æ˜“è®¡ç®—**ï¼šÏƒ'(z) = Ïƒ(z)(1 - Ïƒ(z))\n- **å•è°ƒé€’å¢**ï¼šé€‚åˆæ¦‚ç‡å»ºæ¨¡\n\n### 4.3 ä»£ç å®ç°\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(x):\n    \"\"\"Sigmoid æ¿€æ´»å‡½æ•°\"\"\"\n    return 1 / (1 + np.exp(-x))\n\n# å¯è§†åŒ– Sigmoid å‡½æ•°\nx = np.linspace(-10, 10, 100)\nplt.plot(x, sigmoid(x))\nplt.grid()\nplt.title('Sigmoid Function')\nplt.xlabel('Input')\nplt.ylabel('Output')\nplt.show()\n```\n\n### 4.4 é€»è¾‘å›å½’å®Œæ•´æµç¨‹\n\n```python\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# 1. åŠ è½½æ•°æ®\nX, y = load_breast_cancer(return_X_y=True)\n\n# 2. æ•°æ®åˆ‡åˆ†\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=0\n)\n\n# 3. æ•°æ®æ ‡å‡†åŒ–\nmu = X_train.mean(axis=0)\nsigma = X_train.std(axis=0) + 1e-9\nX_train = (X_train - mu) / sigma\nX_test = (X_test - mu) / sigma\n\n# 4. æ¨¡å‹è®­ç»ƒ\nlr = LogisticRegression()\nlr.fit(X=X_train, y=y_train)\n\n# 5. é¢„æµ‹ä¸è¯„ä¼°\ny_pred = lr.predict(X=X_test)\naccuracy = (y_pred == y_test).mean()\nprint(f\"å‡†ç¡®ç‡: {accuracy:.4f}\")\n\n# æŸ¥çœ‹æ¨¡å‹å‚æ•°\nprint(f\"æƒé‡æ•°é‡: {lr.coef_.shape}\")\nprint(f\"åç½®é¡¹: {lr.intercept_}\")\n```\n\n---\n\n## ğŸ“Š ç¬¬äº”éƒ¨åˆ†ï¼šæ¨¡å‹è¯„ä¼°\n\n### 5.1 å›å½’é—®é¢˜è¯„ä¼°æŒ‡æ ‡\n\n**å‡æ–¹è¯¯å·® (MSE)**ï¼š\n\nMSE = (1/n) Ã— Î£áµ¢â‚Œâ‚â¿ (yáµ¢ - Å·áµ¢)Â²\n\n```python\nmse = ((y_pred - y_test) ** 2).mean()\n```\n\n**å…¶ä»–å¸¸ç”¨æŒ‡æ ‡**ï¼š\n- **MAE**ï¼šå¹³å‡ç»å¯¹è¯¯å·®\n- **RMSE**ï¼šå‡æ–¹æ ¹è¯¯å·®\n- **RÂ²**ï¼šå†³å®šç³»æ•°\n\n### 5.2 åˆ†ç±»é—®é¢˜è¯„ä¼°æŒ‡æ ‡\n\n**å‡†ç¡®ç‡ (Accuracy)**ï¼š\n\nAccuracy = æ­£ç¡®é¢„æµ‹æ•°é‡ / æ€»é¢„æµ‹æ•°é‡\n\n```python\naccuracy = (y_pred == y_test).mean()\n```\n\n**å…¶ä»–é‡è¦æŒ‡æ ‡**ï¼š\n- **ç²¾ç¡®ç‡ (Precision)**\n- **å¬å›ç‡ (Recall)**\n- **F1-Score**\n- **AUC-ROC**\n\n---\n\n## ğŸ’¾ ç¬¬å…­éƒ¨åˆ†ï¼šæ¨¡å‹ä¿å­˜ä¸åŠ è½½\n\n### 6.1 åºåˆ—åŒ–æ¦‚å¿µ\n\n**æ ¸å¿ƒæ¦‚å¿µ**ï¼š\n- **åºåˆ—åŒ–**ï¼šå°†å†…å­˜ä¸­çš„å¯¹è±¡è½¬åŒ–ä¸ºå­—èŠ‚æµï¼Œä¿å­˜åˆ°ç¡¬ç›˜\n- **ååºåˆ—åŒ–**ï¼šå°†ç¡¬ç›˜ä¸Šçš„æ–‡ä»¶è¯»å…¥ï¼Œè½¬åŒ–ä¸ºå†…å­˜ä¸­çš„å¯¹è±¡\n\n### 6.2 Python åºåˆ—åŒ–å·¥å…·å¯¹æ¯”\n\n| å·¥å…· | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |\n|------|------|----------|\n| **pickle** | åº•å±‚ï¼Œæ“ä½œç›¸å¯¹å¤æ‚ | é€šç”¨Pythonå¯¹è±¡åºåˆ—åŒ– |\n| **joblib** | ä¸Šå±‚ï¼Œæ“ä½œç®€ä¾¿ | ä¸“ä¸ºå¤§å‹NumPyæ•°ç»„å’Œç§‘å­¦è®¡ç®—ä¼˜åŒ– |\n\n### 6.3 ä»£ç ç¤ºä¾‹\n\n**ä½¿ç”¨ pickle ä¿å­˜å•ä¸ªæ¨¡å‹**ï¼š\n\n```python\nimport pickle\n\n# ä¿å­˜æ¨¡å‹\nwith open(\"lr.pickle\", \"wb\") as f:\n    pickle.dump(obj=lr, file=f)\n\n# åŠ è½½æ¨¡å‹\nwith open(\"lr.pickle\", \"rb\") as f:\n    lr_loaded = pickle.load(file=f)\n```\n\n**ä½¿ç”¨ joblib ä¿å­˜å¤šä¸ªæ¨¡å‹**ï¼š\n\n```python\nimport joblib\n\n# ä¿å­˜å¤šä¸ªæ¨¡å‹\njoblib.dump(value=knn, filename=\"knn.joblib\")\njoblib.dump(value=[lr, knn], filename=\"models.joblib\")\n\n# åŠ è½½æ¨¡å‹\nknn_loaded = joblib.load(filename=\"knn.joblib\")\nlr_loaded, knn_loaded = joblib.load(filename=\"models.joblib\")\n```\n\n---\n\n## ğŸ“ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»Ÿè®¡å­¦æ¦‚å¿µï¼šæ–¹å·®\n\n### 7.1 æ–¹å·®çš„ä¸¤ç§ä¼°è®¡æ–¹æ³•\n\n**1. æ€»ä½“æ–¹å·®ï¼ˆæœ‰åä¼°è®¡ï¼‰**ï¼š\n\nÏƒÂ² = (1/N) Ã— Î£áµ¢â‚Œâ‚á´º (xáµ¢ - Î¼)Â²\n\n**2. æ ·æœ¬æ–¹å·®ï¼ˆæ— åä¼°è®¡ï¼‰**ï¼š\n\nsÂ² = (1/(N-1)) Ã— Î£áµ¢â‚Œâ‚á´º (xáµ¢ - xÌ„)Â²\n\n### 7.2 åº“å‡½æ•°å·®å¼‚\n\n| åº“ | é»˜è®¤æ–¹æ³• | å‚æ•°æ§åˆ¶ |\n|-----|----------|----------|\n| **NumPy** | æœ‰åä¼°è®¡ (é™¤ä»¥N) | ddof=1 ä½¿ç”¨æ— åä¼°è®¡ |\n| **PyTorch** | æ— åä¼°è®¡ (é™¤ä»¥N-1) | correction=1 æ§åˆ¶ |\n\n### 7.3 ä»£ç ç¤ºä¾‹\n\n```python\nimport numpy as np\nimport torch\n\nls = [1, 2, 3, 4, 5, 6]\n\n# NumPy - é»˜è®¤æœ‰åä¼°è®¡\narr = np.array(ls)\nbiased_std = arr.std()        # æœ‰å\nunbiased_std = arr.std(ddof=1)  # æ— å\n\n# PyTorch - é»˜è®¤æ— åä¼°è®¡\nt = torch.tensor(ls, dtype=torch.float32)\nunbiased_std = t.std(correction=1)  # æ— å\n```\n\n### 7.4 æ³¨æ„äº‹é¡¹\n\n1. **é˜²æ­¢é™¤é›¶é”™è¯¯**ï¼š\n```python\nsigma = X_train.std(axis=0) + 1e-9\n```\n\n2. **é€‰æ‹©åˆé€‚çš„ä¼°è®¡æ–¹æ³•**ï¼š\n   - æ ·æœ¬é‡è¾ƒå°æ—¶ï¼Œä½¿ç”¨æ— åä¼°è®¡æ›´å‡†ç¡®\n   - æ·±åº¦å­¦ä¹ ä¸­ï¼Œé€šå¸¸ä½¿ç”¨æœ‰åä¼°è®¡ï¼ˆè®¡ç®—æ•ˆç‡æ›´é«˜ï¼‰\n\n---\n\n## ğŸš€ ç¬¬å…«éƒ¨åˆ†ï¼šKNNç®—æ³•è¡¥å……\n\n### 8.1 Kè¿‘é‚»ç®—æ³•ç‰¹ç‚¹\n\n**æ ¸å¿ƒç‰¹æ€§**ï¼š\n- **éå‚æ•°æ–¹æ³•**ï¼šä¸éœ€è¦å‡è®¾æ•°æ®åˆ†å¸ƒ\n- **æ‡’æƒ°å­¦ä¹ **ï¼šè®­ç»ƒé˜¶æ®µåªå­˜å‚¨æ•°æ®ï¼Œé¢„æµ‹æ—¶æ‰è®¡ç®—\n- **é€‚ç”¨æ€§å¹¿**ï¼šå›å½’å’Œåˆ†ç±»é—®é¢˜éƒ½é€‚ç”¨\n\n### 8.2 ä»£ç ç¤ºä¾‹\n\n```python\nfrom sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n\n# å›å½’ä»»åŠ¡\nknn_reg = KNeighborsRegressor(n_neighbors=5)\nknn_reg.fit(X=X_train, y=y_train)\n\n# åˆ†ç±»ä»»åŠ¡\nknn_clf = KNeighborsClassifier(n_neighbors=5)\nknn_clf.fit(X=X_train, y=y_train)\n```\n\n---\n\n## ğŸ¯ å…³é”®è¦ç‚¹æ€»ç»“\n\n### âœ… æœ€ä½³å®è·µ\n\n1. **æ•°æ®é¢„å¤„ç†å¿…ä¸å¯å°‘**ï¼šæ ‡å‡†åŒ–èƒ½æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½\n2. **åˆç†åˆ’åˆ†æ•°æ®é›†**ï¼šè®­ç»ƒé›†ç”¨äºå­¦ä¹ ï¼Œæµ‹è¯•é›†ç”¨äºè¯„ä¼°\n3. **é€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡**ï¼šMSEç”¨äºå›å½’ï¼Œå‡†ç¡®ç‡ç”¨äºåˆ†ç±»\n4. **æ¨¡å‹ä¿å­˜å¾ˆé‡è¦**ï¼šä½¿ç”¨joblibä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹\n\n### ğŸ” æ·±å…¥ç†è§£\n\n1. **çº¿æ€§å›å½’**ï¼šé€‚ç”¨äºçº¿æ€§å…³ç³»æ˜æ˜¾çš„å›å½’é—®é¢˜\n2. **é€»è¾‘å›å½’**ï¼šé€šè¿‡Sigmoidå‡½æ•°å®ç°åˆ†ç±»ï¼Œæœ¬è´¨ä¸Šæ˜¯çº¿æ€§åˆ†ç±»å™¨\n3. **æ–¹å·®ä¼°è®¡**ï¼šç†è§£æœ‰åä¸æ— åçš„åŒºåˆ«ï¼Œæ ¹æ®åœºæ™¯é€‰æ‹©\n\n### ğŸ“ˆ è¿›é˜¶æ–¹å‘\n\n- **æ­£åˆ™åŒ–æ–¹æ³•**ï¼ˆRidgeã€Lassoï¼‰\n- **æ¨¡å‹é€‰æ‹©ä¸äº¤å‰éªŒè¯**\n- **ç‰¹å¾å·¥ç¨‹æŠ€å·§**\n- **é›†æˆå­¦ä¹ æ–¹æ³•**\n\n---\n\n## å­¦ä¹ å¿ƒå¾—\n\nè¿™èŠ‚è¯¾æ·±å…¥å­¦ä¹ äº†æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒç®—æ³•å’Œå®è·µæŠ€å·§ï¼š\n\n1. **æ•°æ®é¢„å¤„ç†çš„é‡è¦æ€§**ï¼šæ ‡å‡†åŒ–ä¸ä»…æ˜¯æŠ€æœ¯è¦æ±‚ï¼Œæ›´æ˜¯ä¿è¯æ¨¡å‹å…¬å¹³æ€§çš„å…³é”®æ­¥éª¤\n2. **çº¿æ€§æ¨¡å‹çš„å¨åŠ›**ï¼šè™½ç„¶ç®€å•ï¼Œä½†çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’åœ¨å¾ˆå¤šå®é™…é—®é¢˜ä¸­éƒ½è¡¨ç°ä¼˜å¼‚\n3. **æ¨¡å‹è¯„ä¼°çš„ç§‘å­¦æ€§**ï¼šé€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡å¯¹æ¨¡å‹æ€§èƒ½åˆ¤æ–­è‡³å…³é‡è¦\n4. **å·¥ç¨‹å®è·µçš„ä»·å€¼**ï¼šæ¨¡å‹ä¿å­˜ã€åŠ è½½ç­‰å·¥ç¨‹æŠ€å·§æ˜¯å®é™…éƒ¨ç½²çš„å¿…å¤‡æŠ€èƒ½\n\n## ä¸‹ä¸€æ­¥å­¦ä¹ è®¡åˆ’\n- æ·±å…¥å­¦ä¹ æ­£åˆ™åŒ–æŠ€æœ¯\n- æ¢ç´¢æ›´å¤æ‚çš„éçº¿æ€§æ¨¡å‹\n- å®è·µç‰¹å¾å·¥ç¨‹æŠ€å·§\n- å­¦ä¹ æ¨¡å‹è°ƒä¼˜æ–¹æ³•\n",
    "html": "<h1>æœºå™¨å­¦ä¹ 03 - AIE54 Day03å­¦ä¹ ç¬”è®°</h1>\n<blockquote>\n<p><strong>å­¦ä¹ æ—¥æœŸ</strong>ï¼š2024-06-17<br>\n<strong>ä¸»è®²è€å¸ˆ</strong>ï¼šææ™“å<br>\n<strong>è¯¾æ—¶</strong>ï¼š2<br>\n<strong>æ–‡æ¡£æ¥æº</strong>ï¼šday03-æœºå™¨å­¦ä¹ 03.pdf</p>\n</blockquote>\n<h2>è¯¾ç¨‹å…³é”®è¯</h2>\n<p>æœºå™¨å­¦ä¹  | æ•°æ®é¢„å¤„ç† | çº¿æ€§å›å½’ | é€»è¾‘å›å½’ | æ¨¡å‹è¯„ä¼° | KNNç®—æ³•</p>\n<hr>\n<h2>ğŸ¯ ç¬¬ä¸€éƒ¨åˆ†ï¼šæœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µ</h2>\n<h3>1.1 æœ‰ç›‘ç£å­¦ä¹ æµç¨‹</h3>\n<p><strong>æ ‡å‡†æœºå™¨å­¦ä¹ æµç¨‹</strong>åŒ…æ‹¬ä»¥ä¸‹å…³é”®æ­¥éª¤ï¼š</p>\n<ol>\n<li><strong>æ•°æ®æ”¶é›†ä¸åŠ è½½</strong></li>\n<li><strong>ç‰¹å¾å·¥ç¨‹ä¸æ•°æ®é¢„å¤„ç†</strong></li>\n<li><strong>æ¨¡å‹é€‰æ‹©ä¸è®­ç»ƒ</strong></li>\n<li><strong>æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–</strong></li>\n<li><strong>æ¨¡å‹éƒ¨ç½²ä¸ä¿å­˜</strong></li>\n</ol>\n<h3>1.2 å›å½’ vs åˆ†ç±»</h3>\n<p><strong>æ ¸å¿ƒåŒºåˆ«</strong>ï¼š</p>\n<ul>\n<li><strong>å›å½’é—®é¢˜</strong>ï¼šé¢„æµ‹è¿ç»­æ•°å€¼ï¼ˆå¦‚æˆ¿ä»·é¢„æµ‹ã€æ¸©åº¦é¢„æµ‹ï¼‰</li>\n<li><strong>åˆ†ç±»é—®é¢˜</strong>ï¼šé¢„æµ‹ç¦»æ•£ç±»åˆ«ï¼ˆå¦‚ç–¾ç—…è¯Šæ–­ã€å›¾åƒè¯†åˆ«ï¼‰</li>\n</ul>\n<p><strong>åº”ç”¨åœºæ™¯</strong>ï¼š</p>\n<ul>\n<li>å›å½’ï¼šè‚¡ä»·é¢„æµ‹ã€é”€é‡é¢„æµ‹ã€å¹´é¾„ä¼°è®¡</li>\n<li>åˆ†ç±»ï¼šåƒåœ¾é‚®ä»¶æ£€æµ‹ã€æƒ…æ„Ÿåˆ†æã€åŒ»ç–—è¯Šæ–­</li>\n</ul>\n<hr>\n<h2>ğŸ”§ ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®é¢„å¤„ç†ä¸æ ‡å‡†åŒ–</h2>\n<h3>2.1 æ•°æ®æ ‡å‡†åŒ–çš„é‡è¦æ€§</h3>\n<p><strong>æ ¸å¿ƒç›®çš„</strong>ï¼šæ¶ˆé™¤ä¸åŒç‰¹å¾ä¹‹é—´é‡çº²å·®å¼‚çš„å½±å“ï¼Œç¡®ä¿æ‰€æœ‰ç‰¹å¾åœ¨ç›¸åŒå°ºåº¦ä¸Šå‚ä¸æ¨¡å‹è®­ç»ƒã€‚</p>\n<p><strong>ä¸ºä»€ä¹ˆéœ€è¦æ ‡å‡†åŒ–ï¼Ÿ</strong></p>\n<ul>\n<li>ä¸åŒç‰¹å¾çš„æ•°å€¼èŒƒå›´å¯èƒ½ç›¸å·®å·¨å¤§</li>\n<li>å¤§æ•°å€¼ç‰¹å¾ä¼šä¸»å¯¼æ¨¡å‹å­¦ä¹ è¿‡ç¨‹</li>\n<li>å½±å“åŸºäºè·ç¦»çš„ç®—æ³•ï¼ˆå¦‚KNNã€SVMï¼‰</li>\n</ul>\n<h3>2.2 æ ‡å‡†åŒ–å…¬å¼</h3>\n<p><strong>Z-score æ ‡å‡†åŒ–å…¬å¼</strong>ï¼š</p>\n<p>X_normalized = (X - Î¼) / (Ïƒ + Îµ)</p>\n<p>å…¶ä¸­ï¼š</p>\n<ul>\n<li>Î¼ æ˜¯å‡å€¼</li>\n<li>Ïƒ æ˜¯æ ‡å‡†å·®</li>\n<li>Îµ = 1e-9 æ˜¯é˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°</li>\n</ul>\n<h3>2.3 ä»£ç å®ç°</h3>\n<pre><code class=\"language-python\"># è®¡ç®—è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·®\nmu = X_train.mean(axis=0)\nsigma = X_train.std(axis=0) + 1e-9\n\n# å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œæ ‡å‡†åŒ–\nX_train = (X_train - mu) / sigma\nX_test = (X_test - mu) / sigma\n</code></pre>\n<p><strong>âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹</strong>ï¼š</p>\n<ul>\n<li>æµ‹è¯•é›†å¿…é¡»ä½¿ç”¨è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·®è¿›è¡Œæ ‡å‡†åŒ–</li>\n<li>é¿å…æ•°æ®æ³„éœ²é—®é¢˜</li>\n<li>ä¿è¯æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›</li>\n</ul>\n<hr>\n<h2>ğŸ“ˆ ç¬¬ä¸‰éƒ¨åˆ†ï¼šçº¿æ€§å›å½’</h2>\n<h3>3.1 ç†è®ºåŸºç¡€</h3>\n<p><strong>çº¿æ€§å›å½’å‡è®¾</strong>ï¼šç›®æ ‡å˜é‡ä¸ç‰¹å¾å˜é‡ä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»</p>\n<p><strong>æ•°å­¦è¡¨è¾¾å¼</strong>ï¼š\ny = wâ‚€ + wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™ + Îµ</p>\n<p>å…¶ä¸­ï¼š</p>\n<ul>\n<li>y æ˜¯ç›®æ ‡å˜é‡</li>\n<li>wáµ¢ æ˜¯æƒé‡å‚æ•°</li>\n<li>xáµ¢ æ˜¯ç‰¹å¾å˜é‡</li>\n<li>Îµ æ˜¯è¯¯å·®é¡¹</li>\n</ul>\n<h3>3.2 æŸå¤±å‡½æ•°</h3>\n<p>**å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**ä½œä¸ºæŸå¤±å‡½æ•°ï¼š</p>\n<p>MSE = (1/n) Ã— Î£áµ¢â‚Œâ‚â¿ (yáµ¢ - Å·áµ¢)Â²</p>\n<p><strong>ç‰¹ç‚¹</strong>ï¼š</p>\n<ul>\n<li>å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ</li>\n<li>å¯å¯¼ï¼Œä¾¿äºä¼˜åŒ–</li>\n<li>å‡ ä½•æ„ä¹‰æ˜ç¡®</li>\n</ul>\n<h3>3.3 å®Œæ•´ä»£ç ç¤ºä¾‹</h3>\n<pre><code class=\"language-python\">import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# 1. æ•°æ®åŠ è½½\ndata = pd.read_csv(\"boston_house_prices.csv\", skiprows=1)\n\n# 2. ç‰¹å¾å’Œæ ‡ç­¾åˆ†ç¦»\nX = data.loc[:, :\"LSTAT\"].to_numpy()  # ç‰¹å¾\ny = data.loc[:, \"MEDV\"].to_numpy()    # æ ‡ç­¾\n\n# 3. æ•°æ®åˆ‡åˆ†\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=0\n)\n\n# 4. æ•°æ®æ ‡å‡†åŒ–\nmu = X_train.mean(axis=0)\nsigma = X_train.std(axis=0) + 1e-9\nX_train = (X_train - mu) / sigma\nX_test = (X_test - mu) / sigma\n\n# 5. æ¨¡å‹è®­ç»ƒ\nlr = LinearRegression()\nlr.fit(X=X_train, y=y_train)\n\n# 6. é¢„æµ‹ä¸è¯„ä¼°\ny_pred = lr.predict(X=X_test)\nmse = ((y_pred - y_test) ** 2).mean()\nprint(f\"å‡æ–¹è¯¯å·®: {mse}\")\n</code></pre>\n<hr>\n<h2>ğŸ§  ç¬¬å››éƒ¨åˆ†ï¼šé€»è¾‘å›å½’ä¸åˆ†ç±»</h2>\n<h3>4.1 Sigmoid æ¿€æ´»å‡½æ•°</h3>\n<p><strong>æ ¸å¿ƒä½œç”¨</strong>ï¼šå°†çº¿æ€§è¾“å‡ºæ˜ å°„åˆ° (0,1) åŒºé—´ï¼Œè¡¨ç¤ºæ¦‚ç‡</p>\n<p><strong>æ•°å­¦å…¬å¼</strong>ï¼š\nÏƒ(z) = 1 / (1 + e^(-z))</p>\n<h3>4.2 Sigmoid å‡½æ•°ç‰¹æ€§</h3>\n<p><strong>é‡è¦ç‰¹æ€§</strong>ï¼š</p>\n<ul>\n<li><strong>è¾“å‡ºèŒƒå›´</strong>ï¼š(0, 1)</li>\n<li><strong>Så‹æ›²çº¿</strong>ï¼šå¹³æ»‘çš„æ¦‚ç‡è½¬æ¢</li>\n<li><strong>å¯¼æ•°æ˜“è®¡ç®—</strong>ï¼šÏƒ'(z) = Ïƒ(z)(1 - Ïƒ(z))</li>\n<li><strong>å•è°ƒé€’å¢</strong>ï¼šé€‚åˆæ¦‚ç‡å»ºæ¨¡</li>\n</ul>\n<h3>4.3 ä»£ç å®ç°</h3>\n<pre><code class=\"language-python\">import numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(x):\n    \"\"\"Sigmoid æ¿€æ´»å‡½æ•°\"\"\"\n    return 1 / (1 + np.exp(-x))\n\n# å¯è§†åŒ– Sigmoid å‡½æ•°\nx = np.linspace(-10, 10, 100)\nplt.plot(x, sigmoid(x))\nplt.grid()\nplt.title('Sigmoid Function')\nplt.xlabel('Input')\nplt.ylabel('Output')\nplt.show()\n</code></pre>\n<h3>4.4 é€»è¾‘å›å½’å®Œæ•´æµç¨‹</h3>\n<pre><code class=\"language-python\">from sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# 1. åŠ è½½æ•°æ®\nX, y = load_breast_cancer(return_X_y=True)\n\n# 2. æ•°æ®åˆ‡åˆ†\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=0\n)\n\n# 3. æ•°æ®æ ‡å‡†åŒ–\nmu = X_train.mean(axis=0)\nsigma = X_train.std(axis=0) + 1e-9\nX_train = (X_train - mu) / sigma\nX_test = (X_test - mu) / sigma\n\n# 4. æ¨¡å‹è®­ç»ƒ\nlr = LogisticRegression()\nlr.fit(X=X_train, y=y_train)\n\n# 5. é¢„æµ‹ä¸è¯„ä¼°\ny_pred = lr.predict(X=X_test)\naccuracy = (y_pred == y_test).mean()\nprint(f\"å‡†ç¡®ç‡: {accuracy:.4f}\")\n\n# æŸ¥çœ‹æ¨¡å‹å‚æ•°\nprint(f\"æƒé‡æ•°é‡: {lr.coef_.shape}\")\nprint(f\"åç½®é¡¹: {lr.intercept_}\")\n</code></pre>\n<hr>\n<h2>ğŸ“Š ç¬¬äº”éƒ¨åˆ†ï¼šæ¨¡å‹è¯„ä¼°</h2>\n<h3>5.1 å›å½’é—®é¢˜è¯„ä¼°æŒ‡æ ‡</h3>\n<p><strong>å‡æ–¹è¯¯å·® (MSE)</strong>ï¼š</p>\n<p>MSE = (1/n) Ã— Î£áµ¢â‚Œâ‚â¿ (yáµ¢ - Å·áµ¢)Â²</p>\n<pre><code class=\"language-python\">mse = ((y_pred - y_test) ** 2).mean()\n</code></pre>\n<p><strong>å…¶ä»–å¸¸ç”¨æŒ‡æ ‡</strong>ï¼š</p>\n<ul>\n<li><strong>MAE</strong>ï¼šå¹³å‡ç»å¯¹è¯¯å·®</li>\n<li><strong>RMSE</strong>ï¼šå‡æ–¹æ ¹è¯¯å·®</li>\n<li><strong>RÂ²</strong>ï¼šå†³å®šç³»æ•°</li>\n</ul>\n<h3>5.2 åˆ†ç±»é—®é¢˜è¯„ä¼°æŒ‡æ ‡</h3>\n<p><strong>å‡†ç¡®ç‡ (Accuracy)</strong>ï¼š</p>\n<p>Accuracy = æ­£ç¡®é¢„æµ‹æ•°é‡ / æ€»é¢„æµ‹æ•°é‡</p>\n<pre><code class=\"language-python\">accuracy = (y_pred == y_test).mean()\n</code></pre>\n<p><strong>å…¶ä»–é‡è¦æŒ‡æ ‡</strong>ï¼š</p>\n<ul>\n<li><strong>ç²¾ç¡®ç‡ (Precision)</strong></li>\n<li><strong>å¬å›ç‡ (Recall)</strong></li>\n<li><strong>F1-Score</strong></li>\n<li><strong>AUC-ROC</strong></li>\n</ul>\n<hr>\n<h2>ğŸ’¾ ç¬¬å…­éƒ¨åˆ†ï¼šæ¨¡å‹ä¿å­˜ä¸åŠ è½½</h2>\n<h3>6.1 åºåˆ—åŒ–æ¦‚å¿µ</h3>\n<p><strong>æ ¸å¿ƒæ¦‚å¿µ</strong>ï¼š</p>\n<ul>\n<li><strong>åºåˆ—åŒ–</strong>ï¼šå°†å†…å­˜ä¸­çš„å¯¹è±¡è½¬åŒ–ä¸ºå­—èŠ‚æµï¼Œä¿å­˜åˆ°ç¡¬ç›˜</li>\n<li><strong>ååºåˆ—åŒ–</strong>ï¼šå°†ç¡¬ç›˜ä¸Šçš„æ–‡ä»¶è¯»å…¥ï¼Œè½¬åŒ–ä¸ºå†…å­˜ä¸­çš„å¯¹è±¡</li>\n</ul>\n<h3>6.2 Python åºåˆ—åŒ–å·¥å…·å¯¹æ¯”</h3>\n<p>| å·¥å…· | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |\n|------|------|----------|\n| <strong>pickle</strong> | åº•å±‚ï¼Œæ“ä½œç›¸å¯¹å¤æ‚ | é€šç”¨Pythonå¯¹è±¡åºåˆ—åŒ– |\n| <strong>joblib</strong> | ä¸Šå±‚ï¼Œæ“ä½œç®€ä¾¿ | ä¸“ä¸ºå¤§å‹NumPyæ•°ç»„å’Œç§‘å­¦è®¡ç®—ä¼˜åŒ– |</p>\n<h3>6.3 ä»£ç ç¤ºä¾‹</h3>\n<p><strong>ä½¿ç”¨ pickle ä¿å­˜å•ä¸ªæ¨¡å‹</strong>ï¼š</p>\n<pre><code class=\"language-python\">import pickle\n\n# ä¿å­˜æ¨¡å‹\nwith open(\"lr.pickle\", \"wb\") as f:\n    pickle.dump(obj=lr, file=f)\n\n# åŠ è½½æ¨¡å‹\nwith open(\"lr.pickle\", \"rb\") as f:\n    lr_loaded = pickle.load(file=f)\n</code></pre>\n<p><strong>ä½¿ç”¨ joblib ä¿å­˜å¤šä¸ªæ¨¡å‹</strong>ï¼š</p>\n<pre><code class=\"language-python\">import joblib\n\n# ä¿å­˜å¤šä¸ªæ¨¡å‹\njoblib.dump(value=knn, filename=\"knn.joblib\")\njoblib.dump(value=[lr, knn], filename=\"models.joblib\")\n\n# åŠ è½½æ¨¡å‹\nknn_loaded = joblib.load(filename=\"knn.joblib\")\nlr_loaded, knn_loaded = joblib.load(filename=\"models.joblib\")\n</code></pre>\n<hr>\n<h2>ğŸ“ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»Ÿè®¡å­¦æ¦‚å¿µï¼šæ–¹å·®</h2>\n<h3>7.1 æ–¹å·®çš„ä¸¤ç§ä¼°è®¡æ–¹æ³•</h3>\n<p><strong>1. æ€»ä½“æ–¹å·®ï¼ˆæœ‰åä¼°è®¡ï¼‰</strong>ï¼š</p>\n<p>ÏƒÂ² = (1/N) Ã— Î£áµ¢â‚Œâ‚á´º (xáµ¢ - Î¼)Â²</p>\n<p><strong>2. æ ·æœ¬æ–¹å·®ï¼ˆæ— åä¼°è®¡ï¼‰</strong>ï¼š</p>\n<p>sÂ² = (1/(N-1)) Ã— Î£áµ¢â‚Œâ‚á´º (xáµ¢ - xÌ„)Â²</p>\n<h3>7.2 åº“å‡½æ•°å·®å¼‚</h3>\n<p>| åº“ | é»˜è®¤æ–¹æ³• | å‚æ•°æ§åˆ¶ |\n|-----|----------|----------|\n| <strong>NumPy</strong> | æœ‰åä¼°è®¡ (é™¤ä»¥N) | ddof=1 ä½¿ç”¨æ— åä¼°è®¡ |\n| <strong>PyTorch</strong> | æ— åä¼°è®¡ (é™¤ä»¥N-1) | correction=1 æ§åˆ¶ |</p>\n<h3>7.3 ä»£ç ç¤ºä¾‹</h3>\n<pre><code class=\"language-python\">import numpy as np\nimport torch\n\nls = [1, 2, 3, 4, 5, 6]\n\n# NumPy - é»˜è®¤æœ‰åä¼°è®¡\narr = np.array(ls)\nbiased_std = arr.std()        # æœ‰å\nunbiased_std = arr.std(ddof=1)  # æ— å\n\n# PyTorch - é»˜è®¤æ— åä¼°è®¡\nt = torch.tensor(ls, dtype=torch.float32)\nunbiased_std = t.std(correction=1)  # æ— å\n</code></pre>\n<h3>7.4 æ³¨æ„äº‹é¡¹</h3>\n<ol>\n<li><strong>é˜²æ­¢é™¤é›¶é”™è¯¯</strong>ï¼š</li>\n</ol>\n<pre><code class=\"language-python\">sigma = X_train.std(axis=0) + 1e-9\n</code></pre>\n<ol start=\"2\">\n<li><strong>é€‰æ‹©åˆé€‚çš„ä¼°è®¡æ–¹æ³•</strong>ï¼š\n<ul>\n<li>æ ·æœ¬é‡è¾ƒå°æ—¶ï¼Œä½¿ç”¨æ— åä¼°è®¡æ›´å‡†ç¡®</li>\n<li>æ·±åº¦å­¦ä¹ ä¸­ï¼Œé€šå¸¸ä½¿ç”¨æœ‰åä¼°è®¡ï¼ˆè®¡ç®—æ•ˆç‡æ›´é«˜ï¼‰</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2>ğŸš€ ç¬¬å…«éƒ¨åˆ†ï¼šKNNç®—æ³•è¡¥å……</h2>\n<h3>8.1 Kè¿‘é‚»ç®—æ³•ç‰¹ç‚¹</h3>\n<p><strong>æ ¸å¿ƒç‰¹æ€§</strong>ï¼š</p>\n<ul>\n<li><strong>éå‚æ•°æ–¹æ³•</strong>ï¼šä¸éœ€è¦å‡è®¾æ•°æ®åˆ†å¸ƒ</li>\n<li><strong>æ‡’æƒ°å­¦ä¹ </strong>ï¼šè®­ç»ƒé˜¶æ®µåªå­˜å‚¨æ•°æ®ï¼Œé¢„æµ‹æ—¶æ‰è®¡ç®—</li>\n<li><strong>é€‚ç”¨æ€§å¹¿</strong>ï¼šå›å½’å’Œåˆ†ç±»é—®é¢˜éƒ½é€‚ç”¨</li>\n</ul>\n<h3>8.2 ä»£ç ç¤ºä¾‹</h3>\n<pre><code class=\"language-python\">from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n\n# å›å½’ä»»åŠ¡\nknn_reg = KNeighborsRegressor(n_neighbors=5)\nknn_reg.fit(X=X_train, y=y_train)\n\n# åˆ†ç±»ä»»åŠ¡\nknn_clf = KNeighborsClassifier(n_neighbors=5)\nknn_clf.fit(X=X_train, y=y_train)\n</code></pre>\n<hr>\n<h2>ğŸ¯ å…³é”®è¦ç‚¹æ€»ç»“</h2>\n<h3>âœ… æœ€ä½³å®è·µ</h3>\n<ol>\n<li><strong>æ•°æ®é¢„å¤„ç†å¿…ä¸å¯å°‘</strong>ï¼šæ ‡å‡†åŒ–èƒ½æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½</li>\n<li><strong>åˆç†åˆ’åˆ†æ•°æ®é›†</strong>ï¼šè®­ç»ƒé›†ç”¨äºå­¦ä¹ ï¼Œæµ‹è¯•é›†ç”¨äºè¯„ä¼°</li>\n<li><strong>é€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡</strong>ï¼šMSEç”¨äºå›å½’ï¼Œå‡†ç¡®ç‡ç”¨äºåˆ†ç±»</li>\n<li><strong>æ¨¡å‹ä¿å­˜å¾ˆé‡è¦</strong>ï¼šä½¿ç”¨joblibä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹</li>\n</ol>\n<h3>ğŸ” æ·±å…¥ç†è§£</h3>\n<ol>\n<li><strong>çº¿æ€§å›å½’</strong>ï¼šé€‚ç”¨äºçº¿æ€§å…³ç³»æ˜æ˜¾çš„å›å½’é—®é¢˜</li>\n<li><strong>é€»è¾‘å›å½’</strong>ï¼šé€šè¿‡Sigmoidå‡½æ•°å®ç°åˆ†ç±»ï¼Œæœ¬è´¨ä¸Šæ˜¯çº¿æ€§åˆ†ç±»å™¨</li>\n<li><strong>æ–¹å·®ä¼°è®¡</strong>ï¼šç†è§£æœ‰åä¸æ— åçš„åŒºåˆ«ï¼Œæ ¹æ®åœºæ™¯é€‰æ‹©</li>\n</ol>\n<h3>ğŸ“ˆ è¿›é˜¶æ–¹å‘</h3>\n<ul>\n<li><strong>æ­£åˆ™åŒ–æ–¹æ³•</strong>ï¼ˆRidgeã€Lassoï¼‰</li>\n<li><strong>æ¨¡å‹é€‰æ‹©ä¸äº¤å‰éªŒè¯</strong></li>\n<li><strong>ç‰¹å¾å·¥ç¨‹æŠ€å·§</strong></li>\n<li><strong>é›†æˆå­¦ä¹ æ–¹æ³•</strong></li>\n</ul>\n<hr>\n<h2>å­¦ä¹ å¿ƒå¾—</h2>\n<p>è¿™èŠ‚è¯¾æ·±å…¥å­¦ä¹ äº†æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒç®—æ³•å’Œå®è·µæŠ€å·§ï¼š</p>\n<ol>\n<li><strong>æ•°æ®é¢„å¤„ç†çš„é‡è¦æ€§</strong>ï¼šæ ‡å‡†åŒ–ä¸ä»…æ˜¯æŠ€æœ¯è¦æ±‚ï¼Œæ›´æ˜¯ä¿è¯æ¨¡å‹å…¬å¹³æ€§çš„å…³é”®æ­¥éª¤</li>\n<li><strong>çº¿æ€§æ¨¡å‹çš„å¨åŠ›</strong>ï¼šè™½ç„¶ç®€å•ï¼Œä½†çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’åœ¨å¾ˆå¤šå®é™…é—®é¢˜ä¸­éƒ½è¡¨ç°ä¼˜å¼‚</li>\n<li><strong>æ¨¡å‹è¯„ä¼°çš„ç§‘å­¦æ€§</strong>ï¼šé€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡å¯¹æ¨¡å‹æ€§èƒ½åˆ¤æ–­è‡³å…³é‡è¦</li>\n<li><strong>å·¥ç¨‹å®è·µçš„ä»·å€¼</strong>ï¼šæ¨¡å‹ä¿å­˜ã€åŠ è½½ç­‰å·¥ç¨‹æŠ€å·§æ˜¯å®é™…éƒ¨ç½²çš„å¿…å¤‡æŠ€èƒ½</li>\n</ol>\n<h2>ä¸‹ä¸€æ­¥å­¦ä¹ è®¡åˆ’</h2>\n<ul>\n<li>æ·±å…¥å­¦ä¹ æ­£åˆ™åŒ–æŠ€æœ¯</li>\n<li>æ¢ç´¢æ›´å¤æ‚çš„éçº¿æ€§æ¨¡å‹</li>\n<li>å®è·µç‰¹å¾å·¥ç¨‹æŠ€å·§</li>\n<li>å­¦ä¹ æ¨¡å‹è°ƒä¼˜æ–¹æ³•</li>\n</ul>"
  },
  "_id": "learning-notes/2024-06-17.md",
  "_raw": {
    "sourceFilePath": "learning-notes/2024-06-17.md",
    "sourceFileName": "2024-06-17.md",
    "sourceFileDir": "learning-notes",
    "contentType": "markdown",
    "flattenedPath": "learning-notes/2024-06-17"
  },
  "type": "LearningNote",
  "url": "/learning-notes/2024-06-17"
}